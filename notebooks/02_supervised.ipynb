{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d119916",
   "metadata": {},
   "source": [
    "# 03 - Supervised baseline\n",
    "will load data, explore, decide and preprocessing first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3be523b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install if needed\n",
    "#!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "abfbfedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install if needed\n",
    "#!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "304e63f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/amira_salah/.cache/kagglehub/datasets/jp797498e/twitter-entity-sentiment-analysis/versions/2\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"jp797498e/twitter-entity-sentiment-analysis\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9b50ed09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module imports for supervised notebook\n",
    "import pandas as pd\n",
    "import re\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9f45cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import functions from ../scripts\n",
    "import sys\n",
    "sys.path.append('../scripts')\n",
    "from supervised_utils import load_data, preprocess_text, preprocess_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2f5859fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess_text is now imported from scripts/supervised_utils.py\n",
    "# text cleaning for tweets.\n",
    "# - Converts to lowercase\n",
    "# - Removes URLs, mentions and extra punctuation\n",
    "# - Removes extra whitespace\n",
    "# Example usage:\n",
    "# preprocess_text(\"my Name us # amira                          @\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "17432025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment\n",
      "Negative      22358\n",
      "Positive      20655\n",
      "Neutral       18108\n",
      "Irrelevant    12875\n",
      "Name: count, dtype: int64\n",
      "Minority class: Irrelevant (12875 samples)\n",
      "Sample Irrelevant tweets:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Entity</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>2418</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>Appreciate the (sonic) concepts / praxis Valen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>2418</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>Appreciate the (sound) concepts / practices th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>2418</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>Evaluate the (sound) concepts / concepts of Va...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2418</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>Appreciate the (sonic) concepts / praxis Valen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>2418</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>Appreciate by the ( sonic ) electronic concept...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>2418</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>Appreciate the (sonic) conversations / actions...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>2422</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>Loving these new @GhostLifestyle cans!! Anyone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>2422</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>I love these new @ GhostLifestyle cans!! Every...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>2422</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>Love these new @ GhostLive cans!! Does anyone ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>2422</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>Loving these new @GhostLifestyle cans!! Anyone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>2422</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>Loving back these three new @GhostLifestyle ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>2422</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>do these new @GhostLifestyle&lt;unk&gt; They want dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>2424</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>How the hell are we into Halloween month alrea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>2424</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>How the hell are we already into Halloween mon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>2424</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>How the hell are we already in Halloween month?!.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>2424</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>How the hell are March into Halloween month al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>2424</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>How the hell are pulling we into Halloween mon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>2424</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>in the hell are we into Halloween month alread...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>2438</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>I'm in this @CBP video. @DHS_Wolf deceptively ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>2438</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>I'm in this @ CBP video. @ DHS _ Wolf misleadi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID       Entity   Sentiment  \\\n",
       "101  2418  Borderlands  Irrelevant   \n",
       "102  2418  Borderlands  Irrelevant   \n",
       "103  2418  Borderlands  Irrelevant   \n",
       "104  2418  Borderlands  Irrelevant   \n",
       "105  2418  Borderlands  Irrelevant   \n",
       "106  2418  Borderlands  Irrelevant   \n",
       "125  2422  Borderlands  Irrelevant   \n",
       "126  2422  Borderlands  Irrelevant   \n",
       "127  2422  Borderlands  Irrelevant   \n",
       "128  2422  Borderlands  Irrelevant   \n",
       "129  2422  Borderlands  Irrelevant   \n",
       "130  2422  Borderlands  Irrelevant   \n",
       "137  2424  Borderlands  Irrelevant   \n",
       "138  2424  Borderlands  Irrelevant   \n",
       "139  2424  Borderlands  Irrelevant   \n",
       "140  2424  Borderlands  Irrelevant   \n",
       "141  2424  Borderlands  Irrelevant   \n",
       "142  2424  Borderlands  Irrelevant   \n",
       "221  2438  Borderlands  Irrelevant   \n",
       "222  2438  Borderlands  Irrelevant   \n",
       "\n",
       "                                                 Tweet  \n",
       "101  Appreciate the (sonic) concepts / praxis Valen...  \n",
       "102  Appreciate the (sound) concepts / practices th...  \n",
       "103  Evaluate the (sound) concepts / concepts of Va...  \n",
       "104  Appreciate the (sonic) concepts / praxis Valen...  \n",
       "105  Appreciate by the ( sonic ) electronic concept...  \n",
       "106  Appreciate the (sonic) conversations / actions...  \n",
       "125  Loving these new @GhostLifestyle cans!! Anyone...  \n",
       "126  I love these new @ GhostLifestyle cans!! Every...  \n",
       "127  Love these new @ GhostLive cans!! Does anyone ...  \n",
       "128  Loving these new @GhostLifestyle cans!! Anyone...  \n",
       "129  Loving back these three new @GhostLifestyle ca...  \n",
       "130  do these new @GhostLifestyle<unk> They want dr...  \n",
       "137  How the hell are we into Halloween month alrea...  \n",
       "138  How the hell are we already into Halloween mon...  \n",
       "139  How the hell are we already in Halloween month?!.  \n",
       "140  How the hell are March into Halloween month al...  \n",
       "141  How the hell are pulling we into Halloween mon...  \n",
       "142  in the hell are we into Halloween month alread...  \n",
       "221  I'm in this @CBP video. @DHS_Wolf deceptively ...  \n",
       "222  I'm in this @ CBP video. @ DHS _ Wolf misleadi...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Neutral tweets:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Entity</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2403</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Rock-Hard La Varlope, RARE &amp; POWERFUL, HANDSOM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2403</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Rock-Hard La Varlope, RARE &amp; POWERFUL, HANDSOM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2403</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Rock-Hard La Varlope, RARE &amp; POWERFUL, HANDSOM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2403</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Rock-Hard La Vita, RARE BUT POWERFUL, HANDSOME...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2403</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Live Rock - Hard music La la Varlope, RARE &amp; t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2403</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>I-Hard like me, RARE LONDON DE, HANDSOME 2011,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2408</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Check out this epic streamer!.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2408</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Check out this epic streamer!.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2408</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Watch this epic striptease!.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2408</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Check out our epic streamer!.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2408</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Check out this big epic streamer!.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2408</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Check&lt;unk&gt; this epic streamer!.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2409</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Blaming Sight for Tardiness! A little bit of b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2409</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>A bit of borderland. I was called to work tomo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2409</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Guilty of sobriety! A bit of a borderline. I w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2409</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Blaming Sight for Tardiness! A little bit of b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2409</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>for Blaming Sight for Tardiness! A little bit ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2409</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2411</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>. . [</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2411</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>.. [</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID       Entity Sentiment  \\\n",
       "12  2403  Borderlands   Neutral   \n",
       "13  2403  Borderlands   Neutral   \n",
       "14  2403  Borderlands   Neutral   \n",
       "15  2403  Borderlands   Neutral   \n",
       "16  2403  Borderlands   Neutral   \n",
       "17  2403  Borderlands   Neutral   \n",
       "42  2408  Borderlands   Neutral   \n",
       "43  2408  Borderlands   Neutral   \n",
       "44  2408  Borderlands   Neutral   \n",
       "45  2408  Borderlands   Neutral   \n",
       "46  2408  Borderlands   Neutral   \n",
       "47  2408  Borderlands   Neutral   \n",
       "48  2409  Borderlands   Neutral   \n",
       "49  2409  Borderlands   Neutral   \n",
       "50  2409  Borderlands   Neutral   \n",
       "51  2409  Borderlands   Neutral   \n",
       "52  2409  Borderlands   Neutral   \n",
       "53  2409  Borderlands   Neutral   \n",
       "60  2411  Borderlands   Neutral   \n",
       "61  2411  Borderlands   Neutral   \n",
       "\n",
       "                                                Tweet  \n",
       "12  Rock-Hard La Varlope, RARE & POWERFUL, HANDSOM...  \n",
       "13  Rock-Hard La Varlope, RARE & POWERFUL, HANDSOM...  \n",
       "14  Rock-Hard La Varlope, RARE & POWERFUL, HANDSOM...  \n",
       "15  Rock-Hard La Vita, RARE BUT POWERFUL, HANDSOME...  \n",
       "16  Live Rock - Hard music La la Varlope, RARE & t...  \n",
       "17  I-Hard like me, RARE LONDON DE, HANDSOME 2011,...  \n",
       "42                   Check out this epic streamer!.    \n",
       "43                     Check out this epic streamer!.  \n",
       "44                       Watch this epic striptease!.  \n",
       "45                      Check out our epic streamer!.  \n",
       "46                 Check out this big epic streamer!.  \n",
       "47                    Check<unk> this epic streamer!.  \n",
       "48  Blaming Sight for Tardiness! A little bit of b...  \n",
       "49  A bit of borderland. I was called to work tomo...  \n",
       "50  Guilty of sobriety! A bit of a borderline. I w...  \n",
       "51  Blaming Sight for Tardiness! A little bit of b...  \n",
       "52  for Blaming Sight for Tardiness! A little bit ...  \n",
       "53                                                all  \n",
       "60                                            . . [    \n",
       "61                                               .. [  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# just explore \n",
    "df = load_data()\n",
    "counts = df['Sentiment'].value_counts()\n",
    "print(counts)\n",
    "minority_label = counts.idxmin()\n",
    "minority_count = counts.min()\n",
    "print(f'Minority class: {minority_label} ({minority_count} samples)')\n",
    "\n",
    "print(\"Sample Irrelevant tweets:\")\n",
    "display(df[df['Sentiment'] == 'Irrelevant'].head(20))\n",
    "print(\"Sample Neutral tweets:\")\n",
    "display(df[df['Sentiment'] == 'Neutral'].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0fb85280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess_df is now imported from scripts/supervised_utils.py\n",
    "# Apply preprocessing to DataFrame and add new columns.\n",
    "# Adds:\n",
    "#   - processed_text\n",
    "#   - label (integer mapping for sentiment)\n",
    "# Example usage:\n",
    "# preprocess_df(load_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "93375367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preview before preprocessing (first 5 rows):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Entity</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting into borderlands and i can murder y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2402</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>So I spent a few hours making something for fu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2402</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>So I spent a couple of hours doing something f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2402</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>So I spent a few hours doing something for fun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2402</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>So I spent a few hours making something for fu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID       Entity Sentiment  \\\n",
       "0  2401  Borderlands  Positive   \n",
       "1  2401  Borderlands  Positive   \n",
       "2  2401  Borderlands  Positive   \n",
       "3  2401  Borderlands  Positive   \n",
       "4  2401  Borderlands  Positive   \n",
       "5  2401  Borderlands  Positive   \n",
       "6  2402  Borderlands  Positive   \n",
       "7  2402  Borderlands  Positive   \n",
       "8  2402  Borderlands  Positive   \n",
       "9  2402  Borderlands  Positive   \n",
       "\n",
       "                                               Tweet  \n",
       "0  im getting on borderlands and i will murder yo...  \n",
       "1  I am coming to the borders and I will kill you...  \n",
       "2  im getting on borderlands and i will kill you ...  \n",
       "3  im coming on borderlands and i will murder you...  \n",
       "4  im getting on borderlands 2 and i will murder ...  \n",
       "5  im getting into borderlands and i can murder y...  \n",
       "6  So I spent a few hours making something for fu...  \n",
       "7  So I spent a couple of hours doing something f...  \n",
       "8  So I spent a few hours doing something for fun...  \n",
       "9  So I spent a few hours making something for fu...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# start using functions\n",
    "# explore before preprocessing\n",
    "df = load_data()\n",
    "print('\\nPreview before preprocessing (first 5 rows):')\n",
    "display(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "03d4b479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install if needed\n",
    "#!pip install scikit-learn imbalanced-learn joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2b39a76c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preview after preprocessing (first 5 rows):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "      <td>i am coming to the borders and i will kill you...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "      <td>im getting on borderlands and i will kill you all</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>im getting into borderlands and i can murder y...</td>\n",
       "      <td>im getting into borderlands and i can murder y...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>So I spent a few hours making something for fu...</td>\n",
       "      <td>so i spent a few hours making something for fu...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>So I spent a couple of hours doing something f...</td>\n",
       "      <td>so i spent a couple of hours doing something f...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>So I spent a few hours doing something for fun...</td>\n",
       "      <td>so i spent a few hours doing something for fun...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>So I spent a few hours making something for fu...</td>\n",
       "      <td>so i spent a few hours making something for fu...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  \\\n",
       "0  im getting on borderlands and i will murder yo...   \n",
       "1  I am coming to the borders and I will kill you...   \n",
       "2  im getting on borderlands and i will kill you ...   \n",
       "3  im coming on borderlands and i will murder you...   \n",
       "4  im getting on borderlands 2 and i will murder ...   \n",
       "5  im getting into borderlands and i can murder y...   \n",
       "6  So I spent a few hours making something for fu...   \n",
       "7  So I spent a couple of hours doing something f...   \n",
       "8  So I spent a few hours doing something for fun...   \n",
       "9  So I spent a few hours making something for fu...   \n",
       "\n",
       "                                      processed_text Sentiment  label  \n",
       "0  im getting on borderlands and i will murder yo...  Positive      2  \n",
       "1  i am coming to the borders and i will kill you...  Positive      2  \n",
       "2  im getting on borderlands and i will kill you all  Positive      2  \n",
       "3  im coming on borderlands and i will murder you...  Positive      2  \n",
       "4  im getting on borderlands 2 and i will murder ...  Positive      2  \n",
       "5  im getting into borderlands and i can murder y...  Positive      2  \n",
       "6  so i spent a few hours making something for fu...  Positive      2  \n",
       "7  so i spent a couple of hours doing something f...  Positive      2  \n",
       "8  so i spent a few hours doing something for fun...  Positive      2  \n",
       "9  so i spent a few hours making something for fu...  Positive      2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# preprocessing df\n",
    "proc_df = preprocess_df(df)\n",
    "\n",
    "# explore after preprocessing\n",
    "print('\\nPreview after preprocessing (first 5 rows):')\n",
    "display(proc_df.head(10)[['Tweet', 'processed_text', 'Sentiment', 'label']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfbe0d5",
   "metadata": {},
   "source": [
    "# Supervised ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "46739ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "\n",
    "# Create model output directory - organize\n",
    "models_dir = Path('../models')\n",
    "models_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Prepare\n",
    "base_tfidf = TfidfVectorizer(sublinear_tf=True, max_df=0.95, min_df=3)\n",
    "base_tfidf_ngram12 = TfidfVectorizer(sublinear_tf=True, max_df=0.95, min_df=3, ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "583c1244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg_vectorizer_config = dict(sublinear_tf=True, max_df=0.95, min_df=3)\n",
    "logreg_clf = LogisticRegression(max_iter=2000, class_weight='balanced', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cf3b3fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment\n",
      "Neutral     30983\n",
      "Negative    22358\n",
      "Positive    20655\n",
      "Name: count, dtype: int64\n",
      "Minority class: Positive (20655 samples)\n"
     ]
    }
   ],
   "source": [
    "# just explore agian \n",
    "counts = proc_df['Sentiment'].value_counts()\n",
    "print(counts)\n",
    "minority_label = counts.idxmin()\n",
    "minority_count = counts.min()\n",
    "print(f'Minority class: {minority_label} ({minority_count} samples)')\n",
    "\n",
    "# minority class: Positive (20832 samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8c6cf2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForest \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "rf_vectorizer_config = dict(sublinear_tf=True, max_df=0.95, min_df=3, ngram_range=(1,2))\n",
    "rf_clf = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "ros = RandomOverSampler(random_state=42) # Handle class imbalance with duplicate minority class samples(Positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ba4cd35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear SVM\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svm_vectorizer_config = dict(sublinear_tf=True, max_df=0.95, min_df=3)\n",
    "svm_clf = LinearSVC(max_iter=10000, class_weight='balanced', random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fe833576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data, scoring and cross-validation\n",
    "try:\n",
    "    proc_df\n",
    "except NameError: # if error or not found load data again and preprocess\n",
    "    df = load_data()\n",
    "    proc_df = preprocess_df(df)\n",
    "\n",
    "X = proc_df['processed_text'].values\n",
    "y = proc_df['Sentiment'].values\n",
    "\n",
    "# Define the metrics we care about\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision_macro': make_scorer(precision_score, average='macro', zero_division=0),\n",
    "    'recall_macro': make_scorer(recall_score, average='macro', zero_division=0),\n",
    "    'f1_macro': make_scorer(f1_score, average='macro', zero_division=0)\n",
    "}\n",
    "\n",
    "# cross validation\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "05133da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg CV:\n",
      "- accuracy 0.8030028362033228\n",
      "- precision 0.7996794553020705\n",
      "- recall 0.8073381213940338\n",
      "- f1 0.8025866563389773\n"
     ]
    }
   ],
   "source": [
    "# 1) Cross-validation for Logistic Regression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "logreg_scores = {'accuracy':[], 'precision':[], 'recall':[], 'f1':[]}\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(cv.split(X, y), 1):\n",
    "\n",
    "    X_train_text = X[train_idx]\n",
    "    y_train = y[train_idx]\n",
    "\n",
    "    X_test_text = X[test_idx]\n",
    "    y_test = y[test_idx]\n",
    "\n",
    "    vec = TfidfVectorizer(**logreg_vectorizer_config)\n",
    "    X_train_vec = vec.fit_transform(X_train_text)\n",
    "    X_test_vec = vec.transform(X_test_text)\n",
    "\n",
    "    clf = LogisticRegression(max_iter=2000, class_weight='balanced', random_state=42)\n",
    "    clf.fit(X_train_vec, y_train)\n",
    "    preds = clf.predict(X_test_vec)\n",
    "\n",
    "    # prepare results\n",
    "    logreg_scores['accuracy'].append(accuracy_score(y_test, preds))\n",
    "    logreg_scores['precision'].append(precision_score(y_test, preds, average='macro', zero_division=0))\n",
    "    logreg_scores['recall'].append(recall_score(y_test, preds, average='macro', zero_division=0))\n",
    "    logreg_scores['f1'].append(f1_score(y_test, preds, average='macro', zero_division=0))\n",
    "\n",
    "print('LogReg CV:')\n",
    "for k,v in logreg_scores.items():\n",
    "    print('-', k, sum(v)/len(v))\n",
    "\n",
    "cv_results = {'Logistic Regression': logreg_scores}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a714379a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest CV:\n",
      "- accuracy 0.5680307334498497\n",
      "- precision 0.5936903649763224\n",
      "- recall 0.5949875295261942\n",
      "- f1 0.567473493638756\n"
     ]
    }
   ],
   "source": [
    "# 2) Cross-validation for RandomForest\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "rf_scores = {'accuracy':[], 'precision':[], 'recall':[], 'f1':[]}\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(cv.split(X, y), 1):\n",
    "\n",
    "    X_train_text = X[train_idx]\n",
    "    y_train = y[train_idx]\n",
    "\n",
    "    X_test_text = X[test_idx]\n",
    "    y_test = y[test_idx]\n",
    "\n",
    "    vec = TfidfVectorizer(**rf_vectorizer_config)\n",
    "    X_train_vec = vec.fit_transform(X_train_text)\n",
    "    X_test_vec = vec.transform(X_test_text)\n",
    "\n",
    "    # oversample the training set\n",
    "    try:\n",
    "        X_train_os, y_train_os = RandomOverSampler(random_state=42).fit_resample(X_train_vec, y_train)\n",
    "    except Exception: # handeled after multiple errors\n",
    "        # some samplers expect dense input; convert if necessary\n",
    "        X_train_os, y_train_os = RandomOverSampler(random_state=42).fit_resample(X_train_vec.toarray(), y_train)\n",
    "    \n",
    "    clf = RandomForestClassifier(n_estimators=200, random_state=42, max_depth=5)\n",
    "    clf.fit(X_train_os, y_train_os)\n",
    "\n",
    "    preds = clf.predict(X_test_vec)\n",
    "\n",
    "    # prepare results\n",
    "    rf_scores['accuracy'].append(accuracy_score(y_test, preds))\n",
    "    rf_scores['precision'].append(precision_score(y_test, preds, average='macro', zero_division=0))\n",
    "    rf_scores['recall'].append(recall_score(y_test, preds, average='macro', zero_division=0))\n",
    "    rf_scores['f1'].append(f1_score(y_test, preds, average='macro', zero_division=0))\n",
    "\n",
    "print('RandomForest CV:')\n",
    "for k,v in rf_scores.items():\n",
    "    print('-', k, sum(v)/len(v))\n",
    "\n",
    "cv_results['rf'] = rf_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87f94da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM CV:\n",
      "- accuracy 0.859857262999874\n",
      "- precision 0.8572663181928558\n",
      "- recall 0.8601736559962607\n",
      "- f1 0.8586094162484642\n"
     ]
    }
   ],
   "source": [
    "# 3) Cross-validation for Linear SVM\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "svm_scores = {'accuracy':[], 'precision':[], 'recall':[], 'f1':[]}\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(cv.split(X, y), 1):\n",
    "\n",
    "    X_train_text = X[train_idx]\n",
    "    y_train = y[train_idx]\n",
    "\n",
    "    X_test_text = X[test_idx]\n",
    "    y_test = y[test_idx]\n",
    "\n",
    "    vec = TfidfVectorizer(**svm_vectorizer_config)\n",
    "    X_train_vec = vec.fit_transform(X_train_text)\n",
    "    X_test_vec = vec.transform(X_test_text)\n",
    "\n",
    "    clf = LinearSVC(max_iter=10000, class_weight='balanced', random_state=42)\n",
    "    clf.fit(X_train_vec, y_train)\n",
    "\n",
    "    preds = clf.predict(X_test_vec)\n",
    "\n",
    "    # prepare results\n",
    "    svm_scores['accuracy'].append(accuracy_score(y_test, preds))\n",
    "    svm_scores['precision'].append(precision_score(y_test, preds, average='macro', zero_division=0))\n",
    "    svm_scores['recall'].append(recall_score(y_test, preds, average='macro', zero_division=0))\n",
    "    svm_scores['f1'].append(f1_score(y_test, preds, average='macro', zero_division=0))\n",
    "\n",
    "print('Linear SVM CV:')\n",
    "for k,v in svm_scores.items():\n",
    "    print('-', k, sum(v)/len(v))\n",
    "\n",
    "cv_results['svm'] = svm_scores\n",
    "# SVM CV is the best acuratest model so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6f45974f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models saved in: ../models\n"
     ]
    }
   ],
   "source": [
    "# Fit final models on FULL dataset and save model \n",
    "\n",
    "# Logistic Regression final fit\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "logreg_vec = TfidfVectorizer(**logreg_vectorizer_config)\n",
    "\n",
    "X_full_vec = logreg_vec.fit_transform(X)\n",
    "\n",
    "logreg_clf_full = LogisticRegression(max_iter=2000, class_weight='balanced', random_state=42)\n",
    "logreg_clf_full.fit(X_full_vec, y)\n",
    "\n",
    "joblib.dump(logreg_vec, models_dir / 'tfidf_vectorizer.joblib')\n",
    "joblib.dump(logreg_clf_full, models_dir / 'logreg_clf.joblib')\n",
    "\n",
    "# RandomForest final fit\n",
    "rf_vec = TfidfVectorizer(**rf_vectorizer_config)\n",
    "X_full_vec_rf = rf_vec.fit_transform(X)\n",
    "# oversample full training set for RandomForest\n",
    "try:\n",
    "    X_os, y_os = RandomOverSampler(random_state=42).fit_resample(X_full_vec_rf, y)\n",
    "except Exception:\n",
    "    X_os, y_os = RandomOverSampler(random_state=42).fit_resample(X_full_vec_rf.toarray(), y)\n",
    "\n",
    "rf_clf_full = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "rf_clf_full.fit(X_os, y_os)\n",
    "\n",
    "joblib.dump(rf_vec, models_dir / 'rf_tfidf_ngram12_vectorizer.joblib')\n",
    "joblib.dump(rf_clf_full, models_dir / 'rf_clf.joblib')\n",
    "\n",
    "# LinearSVC final fit\n",
    "svm_vec = TfidfVectorizer(**svm_vectorizer_config)\n",
    "\n",
    "X_full_vec_svm = svm_vec.fit_transform(X)\n",
    "\n",
    "svm_clf_full = LinearSVC(max_iter=10000, class_weight='balanced', random_state=42)\n",
    "svm_clf_full.fit(X_full_vec_svm, y)\n",
    "\n",
    "joblib.dump(svm_vec, models_dir / 'svm_tfidf_vectorizer.joblib')\n",
    "joblib.dump(svm_clf_full, models_dir / 'svm_clf.joblib')\n",
    "\n",
    "print('models saved in:', models_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "de935dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models list:\n",
      "- logreg_clf.joblib\n",
      "- preprocessed_df.csv\n",
      "- preprocessed_df.parquet\n",
      "- rf_clf.joblib\n",
      "- rf_tfidf_ngram12_vectorizer.joblib\n",
      "- svm_clf.joblib\n",
      "- svm_tfidf_vectorizer.joblib\n",
      "- tfidf_vectorizer.joblib\n"
     ]
    }
   ],
   "source": [
    "# list models saved in ../models/\n",
    "print('models list:')\n",
    "for p in sorted(models_dir.glob('*')):\n",
    "    print('-', p.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "cd4c6940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If needed, install pyarrow\n",
    "# !pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "13a7f6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed DataFrame as parquet for this requirement in streamlit:\n",
    "# Export capabilities for social media reports\n",
    "proc_df.to_parquet('../models/processed_df.parquet', index=False)\n",
    "proc_df.to_csv('../models/processed_df.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BrandWatch (.venv)",
   "language": "python",
   "name": "brandwatch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

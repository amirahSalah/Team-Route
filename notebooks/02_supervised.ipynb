{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d119916",
   "metadata": {},
   "source": [
    "# 03 - Supervised baseline\n",
    "will load data, explore, decide and preprocessing first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3be523b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install if needed\n",
    "#!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abfbfedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install if needed\n",
    "#!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7e42c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd4c6940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If needed, install pyarrow\n",
    "# !pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03d4b479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install if needed\n",
    "#!pip install scikit-learn imbalanced-learn joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "304e63f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amira_salah/Documents/Study/AI & ML Course/Graduation Project/Team-Root-/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/amira_salah/.cache/kagglehub/datasets/jp797498e/twitter-entity-sentiment-analysis/versions/2\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"jp797498e/twitter-entity-sentiment-analysis\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b50ed09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module imports for supervised notebook\n",
    "import pandas as pd\n",
    "import re\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c9f45cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import functions from ../scripts\n",
    "import sys\n",
    "sys.path.append('../scripts')\n",
    "from utils import load_data, preprocess_data, get_wordnet_pos, extract_features, clean_and_tokenize, lemmatize_tokens, vectorize_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93375367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preview before preprocessing (first 5 rows):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Entity</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting into borderlands and i can murder y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2402</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>So I spent a few hours making something for fu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2402</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>So I spent a couple of hours doing something f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2402</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>So I spent a few hours doing something for fun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2402</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>So I spent a few hours making something for fu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID       Entity Sentiment  \\\n",
       "0  2401  Borderlands  Positive   \n",
       "1  2401  Borderlands  Positive   \n",
       "2  2401  Borderlands  Positive   \n",
       "3  2401  Borderlands  Positive   \n",
       "4  2401  Borderlands  Positive   \n",
       "5  2401  Borderlands  Positive   \n",
       "6  2402  Borderlands  Positive   \n",
       "7  2402  Borderlands  Positive   \n",
       "8  2402  Borderlands  Positive   \n",
       "9  2402  Borderlands  Positive   \n",
       "\n",
       "                                               Tweet  \n",
       "0  im getting on borderlands and i will murder yo...  \n",
       "1  I am coming to the borders and I will kill you...  \n",
       "2  im getting on borderlands and i will kill you ...  \n",
       "3  im coming on borderlands and i will murder you...  \n",
       "4  im getting on borderlands 2 and i will murder ...  \n",
       "5  im getting into borderlands and i can murder y...  \n",
       "6  So I spent a few hours making something for fu...  \n",
       "7  So I spent a couple of hours doing something f...  \n",
       "8  So I spent a few hours doing something for fun...  \n",
       "9  So I spent a few hours making something for fu...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# start using functions\n",
    "# explore before preprocessing\n",
    "df = load_data()\n",
    "print('\\nPreview before preprocessing (first 10 rows):')\n",
    "display(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b39a76c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preview after preprocessing (first 10 rows):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Entity</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>mentions</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[im, getting, on, borderlands, and, i, will, m...</td>\n",
       "      <td>[im, get, on, borderland, and, i, will, murder...</td>\n",
       "      <td>im get on borderland and i will murder you all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[I, am, coming, to, the, borders, and, I, will...</td>\n",
       "      <td>[I, be, come, to, the, border, and, I, will, k...</td>\n",
       "      <td>I be come to the border and I will kill you all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[im, getting, on, borderlands, and, i, will, k...</td>\n",
       "      <td>[im, get, on, borderland, and, i, will, kill, ...</td>\n",
       "      <td>im get on borderland and i will kill you all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[im, coming, on, borderlands, and, i, will, mu...</td>\n",
       "      <td>[im, come, on, borderland, and, i, will, murde...</td>\n",
       "      <td>im come on borderland and i will murder you all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[im, getting, on, borderlands, 2, and, i, will...</td>\n",
       "      <td>[im, get, on, borderland, 2, and, i, will, mur...</td>\n",
       "      <td>im get on borderland 2 and i will murder you m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting into borderlands and i can murder y...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[im, getting, into, borderlands, and, i, can, ...</td>\n",
       "      <td>[im, get, into, borderland, and, i, can, murde...</td>\n",
       "      <td>im get into borderland and i can murder you all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2402</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>So I spent a few hours making something for fu...</td>\n",
       "      <td></td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>[So, I, spent, a, few, hours, making, somethin...</td>\n",
       "      <td>[So, I, spend, a, few, hour, make, something, ...</td>\n",
       "      <td>So I spend a few hour make something for fun I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2402</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>So I spent a couple of hours doing something f...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[So, I, spent, a, couple, of, hours, doing, so...</td>\n",
       "      <td>[So, I, spend, a, couple, of, hour, do, someth...</td>\n",
       "      <td>So I spend a couple of hour do something for f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2402</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>So I spent a few hours doing something for fun...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[So, I, spent, a, few, hours, doing, something...</td>\n",
       "      <td>[So, I, spend, a, few, hour, do, something, fo...</td>\n",
       "      <td>So I spend a few hour do something for fun If ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2402</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>So I spent a few hours making something for fu...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[So, I, spent, a, few, hours, making, somethin...</td>\n",
       "      <td>[So, I, spend, a, few, hour, make, something, ...</td>\n",
       "      <td>So I spend a few hour make something for fun I...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID       Entity Sentiment  \\\n",
       "0  2401  Borderlands  Positive   \n",
       "1  2401  Borderlands  Positive   \n",
       "2  2401  Borderlands  Positive   \n",
       "3  2401  Borderlands  Positive   \n",
       "4  2401  Borderlands  Positive   \n",
       "5  2401  Borderlands  Positive   \n",
       "6  2402  Borderlands  Positive   \n",
       "7  2402  Borderlands  Positive   \n",
       "8  2402  Borderlands  Positive   \n",
       "9  2402  Borderlands  Positive   \n",
       "\n",
       "                                               Tweet hashtags     mentions  \\\n",
       "0  im getting on borderlands and i will murder yo...                         \n",
       "1  I am coming to the borders and I will kill you...                         \n",
       "2  im getting on borderlands and i will kill you ...                         \n",
       "3  im coming on borderlands and i will murder you...                         \n",
       "4  im getting on borderlands 2 and i will murder ...                         \n",
       "5  im getting into borderlands and i can murder y...                         \n",
       "6  So I spent a few hours making something for fu...           Borderlands   \n",
       "7  So I spent a couple of hours doing something f...                         \n",
       "8  So I spent a few hours doing something for fun...                         \n",
       "9  So I spent a few hours making something for fu...                         \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [im, getting, on, borderlands, and, i, will, m...   \n",
       "1  [I, am, coming, to, the, borders, and, I, will...   \n",
       "2  [im, getting, on, borderlands, and, i, will, k...   \n",
       "3  [im, coming, on, borderlands, and, i, will, mu...   \n",
       "4  [im, getting, on, borderlands, 2, and, i, will...   \n",
       "5  [im, getting, into, borderlands, and, i, can, ...   \n",
       "6  [So, I, spent, a, few, hours, making, somethin...   \n",
       "7  [So, I, spent, a, couple, of, hours, doing, so...   \n",
       "8  [So, I, spent, a, few, hours, doing, something...   \n",
       "9  [So, I, spent, a, few, hours, making, somethin...   \n",
       "\n",
       "                                              lemmas  \\\n",
       "0  [im, get, on, borderland, and, i, will, murder...   \n",
       "1  [I, be, come, to, the, border, and, I, will, k...   \n",
       "2  [im, get, on, borderland, and, i, will, kill, ...   \n",
       "3  [im, come, on, borderland, and, i, will, murde...   \n",
       "4  [im, get, on, borderland, 2, and, i, will, mur...   \n",
       "5  [im, get, into, borderland, and, i, can, murde...   \n",
       "6  [So, I, spend, a, few, hour, make, something, ...   \n",
       "7  [So, I, spend, a, couple, of, hour, do, someth...   \n",
       "8  [So, I, spend, a, few, hour, do, something, fo...   \n",
       "9  [So, I, spend, a, few, hour, make, something, ...   \n",
       "\n",
       "                                      processed_text  \n",
       "0     im get on borderland and i will murder you all  \n",
       "1    I be come to the border and I will kill you all  \n",
       "2       im get on borderland and i will kill you all  \n",
       "3    im come on borderland and i will murder you all  \n",
       "4  im get on borderland 2 and i will murder you m...  \n",
       "5    im get into borderland and i can murder you all  \n",
       "6  So I spend a few hour make something for fun I...  \n",
       "7  So I spend a couple of hour do something for f...  \n",
       "8  So I spend a few hour do something for fun If ...  \n",
       "9  So I spend a few hour make something for fun I...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# preprocessing df\n",
    "proc_df = preprocess_data(df)\n",
    "\n",
    "# explore after preprocessing\n",
    "print('\\nPreview after preprocessing (first 10 rows):')\n",
    "display(proc_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfbe0d5",
   "metadata": {},
   "source": [
    "# Supervised ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3b3fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment\n",
      "Negative      22358\n",
      "Positive      20655\n",
      "Neutral       18108\n",
      "Irrelevant    12875\n",
      "Name: count, dtype: int64\n",
      "Minority class: Irrelevant (12875 samples)\n"
     ]
    }
   ],
   "source": [
    "# just explore class distribution \n",
    "counts = proc_df['Sentiment'].value_counts()\n",
    "print(counts)\n",
    "minority_label = counts.idxmin()\n",
    "minority_count = counts.min()\n",
    "print(f'Minority class: {minority_label} ({minority_count} samples)')\n",
    "\n",
    "# minority class: Irrelevant (12875 samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bce2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Prepare data and split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "X = proc_df['processed_text'].values\n",
    "y = proc_df['Sentiment'].values\n",
    "\n",
    "# Stratified split for fair evaluation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Oversample training set for class imbalance\n",
    "vec = None  # will be defined per model\n",
    "ros = RandomOverSampler(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e511a419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. TF-IDF + Logistic Regression Baseline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "vec = TfidfVectorizer(sublinear_tf=True, max_df=0.95, min_df=3)\n",
    "X_train_vec = vec.fit_transform(X_train)\n",
    "X_test_vec = vec.transform(X_test)\n",
    "\n",
    "try:\n",
    "    X_train_os, y_train_os = ros.fit_resample(X_train_vec, y_train)\n",
    "except Exception:\n",
    "    X_train_os, y_train_os = ros.fit_resample(X_train_vec.toarray(), y_train)\n",
    "\n",
    "logreg = LogisticRegression(max_iter=2000, class_weight='balanced', random_state=42)\n",
    "logreg.fit(X_train_os, y_train_os)\n",
    "y_pred_logreg = logreg.predict(X_test_vec)\n",
    "print('Logistic Regression Test Accuracy:', accuracy_score(y_test, y_pred_logreg))\n",
    "print(classification_report(y_test, y_pred_logreg))\n",
    "\n",
    "cv_scores_logreg = cross_val_score(logreg, vec.transform(X), y, cv=5, scoring='accuracy')\n",
    "print(f'Logistic Regression CV scores: {cv_scores_logreg}')\n",
    "print(f'Logistic Regression Average CV Accuracy: {cv_scores_logreg.mean():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558c0b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Random Forest with n-gram (1,2)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_vec = TfidfVectorizer(sublinear_tf=True, max_df=0.95, min_df=3, ngram_range=(1,2))\n",
    "X_train_vec_rf = rf_vec.fit_transform(X_train)\n",
    "X_test_vec_rf = rf_vec.transform(X_test)\n",
    "\n",
    "try:\n",
    "    X_train_os_rf, y_train_os_rf = ros.fit_resample(X_train_vec_rf, y_train)\n",
    "except Exception:\n",
    "    X_train_os_rf, y_train_os_rf = ros.fit_resample(X_train_vec_rf.toarray(), y_train)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "rf.fit(X_train_os_rf, y_train_os_rf)\n",
    "y_pred_rf = rf.predict(X_test_vec_rf)\n",
    "print('Random Forest Test Accuracy:', accuracy_score(y_test, y_pred_rf))\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "\n",
    "cv_scores_rf = cross_val_score(rf, rf_vec.transform(X), y, cv=5, scoring='accuracy')\n",
    "print(f'Random Forest CV scores: {cv_scores_rf}')\n",
    "print(f'Random Forest Average CV Accuracy: {cv_scores_rf.mean():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5ac8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Linear SVM for Text\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svm_vec = TfidfVectorizer(sublinear_tf=True, max_df=0.95, min_df=3)\n",
    "X_train_vec_svm = svm_vec.fit_transform(X_train)\n",
    "X_test_vec_svm = svm_vec.transform(X_test)\n",
    "\n",
    "try:\n",
    "    X_train_os_svm, y_train_os_svm = ros.fit_resample(X_train_vec_svm, y_train)\n",
    "except Exception:\n",
    "    X_train_os_svm, y_train_os_svm = ros.fit_resample(X_train_vec_svm.toarray(), y_train)\n",
    "\n",
    "svm = LinearSVC(max_iter=10000, class_weight='balanced', random_state=42)\n",
    "svm.fit(X_train_os_svm, y_train_os_svm)\n",
    "y_pred_svm = svm.predict(X_test_vec_svm)\n",
    "print('Linear SVM Test Accuracy:', accuracy_score(y_test, y_pred_svm))\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "\n",
    "cv_scores_svm = cross_val_score(svm, svm_vec.transform(X), y, cv=5, scoring='accuracy')\n",
    "print(f'Linear SVM CV scores: {cv_scores_svm}')\n",
    "print(f'Linear SVM Average CV Accuracy: {cv_scores_svm.mean():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de935dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models list:\n",
      "- logreg_clf.joblib\n",
      "- rf_clf.joblib\n",
      "- rf_tfidf_ngram12_vectorizer.joblib\n",
      "- svm_clf.joblib\n",
      "- svm_tfidf_vectorizer.joblib\n",
      "- tfidf_vectorizer.joblib\n"
     ]
    }
   ],
   "source": [
    "# list models saved in ../models/\n",
    "print('models list:')\n",
    "for p in sorted(models_dir.glob('*')):\n",
    "    print('-', p.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "13a7f6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed DataFrame as parquet for this requirement in streamlit:\n",
    "# Export capabilities for social media reports\n",
    "proc_df.to_parquet('../models/processed_df.parquet', index=False)\n",
    "proc_df.to_csv('../models/processed_df.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
